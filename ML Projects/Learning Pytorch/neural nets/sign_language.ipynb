{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join('../../data', 'sign_language_mnist', 'sign_mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17    1294\n",
      "16    1279\n",
      "11    1241\n",
      "22    1225\n",
      "5     1204\n",
      "18    1199\n",
      "3     1196\n",
      "14    1196\n",
      "19    1186\n",
      "23    1164\n",
      "8     1162\n",
      "20    1161\n",
      "13    1151\n",
      "2     1144\n",
      "0     1126\n",
      "24    1118\n",
      "10    1114\n",
      "6     1090\n",
      "15    1088\n",
      "21    1082\n",
      "12    1055\n",
      "7     1013\n",
      "1     1010\n",
      "4      957\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     13     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_data_path)\n",
    "print(train_data['label'].value_counts())\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PictureDataset(Dataset):\n",
    "    def __init__(self, train_data):\n",
    "        self.training_labels = torch.tensor(train_data['label'].values)\n",
    "        self.training_features = torch.tensor(train_data.drop(columns=['label']).values).reshape(27455, 28, 28)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.training_labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.training_features[idx], self.training_labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(PictureDataset(train_data), batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 250)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(250, 250)\n",
    "        self.fc3 = nn.Linear(250, 25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/429], Loss: 3.1589\n",
      "Epoch [1/50], Step [200/429], Loss: 3.1667\n",
      "Epoch [1/50], Step [300/429], Loss: 3.1782\n",
      "Epoch [1/50], Step [400/429], Loss: 3.1595\n",
      "Epoch [2/50], Step [100/429], Loss: 3.1655\n",
      "Epoch [2/50], Step [200/429], Loss: 3.1690\n",
      "Epoch [2/50], Step [300/429], Loss: 3.1698\n",
      "Epoch [2/50], Step [400/429], Loss: 3.1842\n",
      "Epoch [3/50], Step [100/429], Loss: 3.1858\n",
      "Epoch [3/50], Step [200/429], Loss: 3.1894\n",
      "Epoch [3/50], Step [300/429], Loss: 3.1651\n",
      "Epoch [3/50], Step [400/429], Loss: 3.1727\n",
      "Epoch [4/50], Step [100/429], Loss: 3.1516\n",
      "Epoch [4/50], Step [200/429], Loss: 3.1934\n",
      "Epoch [4/50], Step [300/429], Loss: 3.1661\n",
      "Epoch [4/50], Step [400/429], Loss: 3.1847\n",
      "Epoch [5/50], Step [100/429], Loss: 3.2135\n",
      "Epoch [5/50], Step [200/429], Loss: 3.1625\n",
      "Epoch [5/50], Step [300/429], Loss: 3.1479\n",
      "Epoch [5/50], Step [400/429], Loss: 3.1713\n",
      "Epoch [6/50], Step [100/429], Loss: 3.1892\n",
      "Epoch [6/50], Step [200/429], Loss: 3.2013\n",
      "Epoch [6/50], Step [300/429], Loss: 3.1733\n",
      "Epoch [6/50], Step [400/429], Loss: 3.1844\n",
      "Epoch [7/50], Step [100/429], Loss: 3.1842\n",
      "Epoch [7/50], Step [200/429], Loss: 3.1774\n",
      "Epoch [7/50], Step [300/429], Loss: 3.1700\n",
      "Epoch [7/50], Step [400/429], Loss: 3.1766\n",
      "Epoch [8/50], Step [100/429], Loss: 3.1767\n",
      "Epoch [8/50], Step [200/429], Loss: 3.1927\n",
      "Epoch [8/50], Step [300/429], Loss: 3.1783\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\23den\\Programming\\ML Projects\\Learning Pytorch\\neural nets\\sign_language.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23den/Programming/ML%20Projects/Learning%20Pytorch/neural%20nets/sign_language.ipynb#ch0000013?line=11'>12</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23den/Programming/ML%20Projects/Learning%20Pytorch/neural%20nets/sign_language.ipynb#ch0000013?line=12'>13</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/23den/Programming/ML%20Projects/Learning%20Pytorch/neural%20nets/sign_language.ipynb#ch0000013?line=13'>14</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23den/Programming/ML%20Projects/Learning%20Pytorch/neural%20nets/sign_language.ipynb#ch0000013?line=15'>16</a>\u001b[0m \u001b[39mif\u001b[39;00m (i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23den/Programming/ML%20Projects/Learning%20Pytorch/neural%20nets/sign_language.ipynb#ch0000013?line=16'>17</a>\u001b[0m     \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mEpoch [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m], Step [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m], Loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23den/Programming/ML%20Projects/Learning%20Pytorch/neural%20nets/sign_language.ipynb#ch0000013?line=17'>18</a>\u001b[0m            \u001b[39m.\u001b[39mformat(epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, num_epochs, i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, total_step, loss\u001b[39m.\u001b[39mitem()))\n",
      "File \u001b[1;32mc:\\Users\\23den\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/optimizer.py?line=85'>86</a>\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/optimizer.py?line=86'>87</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/optimizer.py?line=87'>88</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\23den\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/autograd/grad_mode.py?line=23'>24</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\23den\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=137'>138</a>\u001b[0m             \u001b[39m# record the step after step update\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=138'>139</a>\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=140'>141</a>\u001b[0m     F\u001b[39m.\u001b[39;49madam(params_with_grad,\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=141'>142</a>\u001b[0m            grads,\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=142'>143</a>\u001b[0m            exp_avgs,\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=143'>144</a>\u001b[0m            exp_avg_sqs,\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=144'>145</a>\u001b[0m            max_exp_avg_sqs,\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=145'>146</a>\u001b[0m            state_steps,\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=146'>147</a>\u001b[0m            amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=147'>148</a>\u001b[0m            beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=148'>149</a>\u001b[0m            beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=149'>150</a>\u001b[0m            lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=150'>151</a>\u001b[0m            weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=151'>152</a>\u001b[0m            eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=152'>153</a>\u001b[0m            maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/adam.py?line=153'>154</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\23den\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\_functional.py:110\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/_functional.py?line=104'>105</a>\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(bias_correction2))\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/_functional.py?line=108'>109</a>\u001b[0m step_size \u001b[39m=\u001b[39m lr \u001b[39m/\u001b[39m bias_correction1\n\u001b[1;32m--> <a href='file:///c%3A/Users/23den/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/optim/_functional.py?line=109'>110</a>\u001b[0m param\u001b[39m.\u001b[39;49maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 250\n",
    "\n",
    "total_step = len(train_dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_dataloader):  \n",
    "        images = images.reshape(-1, 28*28)\n",
    "        labels = labels\n",
    "        \n",
    "        outputs = model(images.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PictureDataset(Dataset):\n",
    "    def __init__(self, train_data):\n",
    "        self.training_labels = torch.tensor(train_data['label'].values)\n",
    "        self.training_features = torch.tensor(train_data.drop(columns=['label']).values).reshape(len(self.training_labels), 28, 28)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.training_labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.training_features[idx], self.training_labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = os.path.join('../../data', 'sign_language_mnist', 'sign_mnist_test.csv')\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "test_loader = DataLoader(PictureDataset(test_data), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 2.007808142777468 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        labels = labels\n",
    "        outputs = model(images.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80d51ef78edf10dafe6390381350fe95ff353a7dfba1a29380139ac198de4789"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
