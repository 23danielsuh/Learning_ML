{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "num_epochs = 60\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Toy dataset\n",
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168], \n",
    "                    [9.779], [6.182], [7.59], [2.167], [7.042], \n",
    "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573], \n",
    "                    [3.366], [2.596], [2.53], [1.221], [2.827], \n",
    "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(in_features=input_size, out_features=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterian = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:, Loss is 0.23062317073345184\n",
      "Epoch 1000:, Loss is 0.2058335244655609\n",
      "Epoch 2000:, Loss is 0.19100254774093628\n",
      "Epoch 3000:, Loss is 0.18212953209877014\n",
      "Epoch 4000:, Loss is 0.1768210083246231\n",
      "Epoch 5000:, Loss is 0.17364506423473358\n",
      "Epoch 6000:, Loss is 0.17174497246742249\n",
      "Epoch 7000:, Loss is 0.1706082820892334\n",
      "Epoch 8000:, Loss is 0.1699281632900238\n",
      "Epoch 9000:, Loss is 0.1695212572813034\n",
      "Epoch 10000:, Loss is 0.1692778319120407\n",
      "Epoch 11000:, Loss is 0.16913218796253204\n",
      "Epoch 12000:, Loss is 0.16904501616954803\n",
      "Epoch 13000:, Loss is 0.16899292171001434\n",
      "Epoch 14000:, Loss is 0.16896168887615204\n",
      "Epoch 15000:, Loss is 0.16894307732582092\n",
      "Epoch 16000:, Loss is 0.16893190145492554\n",
      "Epoch 17000:, Loss is 0.1689252257347107\n",
      "Epoch 18000:, Loss is 0.16892117261886597\n",
      "Epoch 19000:, Loss is 0.16891880333423615\n",
      "Epoch 20000:, Loss is 0.16891737282276154\n",
      "Epoch 21000:, Loss is 0.16891653835773468\n",
      "Epoch 22000:, Loss is 0.1689160019159317\n",
      "Epoch 23000:, Loss is 0.16891570389270782\n",
      "Epoch 24000:, Loss is 0.1689155250787735\n",
      "Epoch 25000:, Loss is 0.16891540586948395\n",
      "Epoch 26000:, Loss is 0.16891534626483917\n",
      "Epoch 27000:, Loss is 0.16891531646251678\n",
      "Epoch 28000:, Loss is 0.1689153015613556\n",
      "Epoch 29000:, Loss is 0.1689152866601944\n",
      "Epoch 30000:, Loss is 0.16891524195671082\n",
      "Epoch 31000:, Loss is 0.1689153015613556\n",
      "Epoch 32000:, Loss is 0.1689152717590332\n",
      "Epoch 33000:, Loss is 0.1689152866601944\n",
      "Epoch 34000:, Loss is 0.16891524195671082\n",
      "Epoch 35000:, Loss is 0.16891524195671082\n",
      "Epoch 36000:, Loss is 0.16891524195671082\n",
      "Epoch 37000:, Loss is 0.16891524195671082\n",
      "Epoch 38000:, Loss is 0.16891524195671082\n",
      "Epoch 39000:, Loss is 0.16891524195671082\n",
      "Epoch 40000:, Loss is 0.16891524195671082\n",
      "Epoch 41000:, Loss is 0.16891524195671082\n",
      "Epoch 42000:, Loss is 0.16891524195671082\n",
      "Epoch 43000:, Loss is 0.16891524195671082\n",
      "Epoch 44000:, Loss is 0.16891524195671082\n",
      "Epoch 45000:, Loss is 0.16891524195671082\n",
      "Epoch 46000:, Loss is 0.16891524195671082\n",
      "Epoch 47000:, Loss is 0.16891524195671082\n",
      "Epoch 48000:, Loss is 0.16891524195671082\n",
      "Epoch 49000:, Loss is 0.16891524195671082\n",
      "Epoch 50000:, Loss is 0.16891524195671082\n",
      "Epoch 51000:, Loss is 0.16891524195671082\n",
      "Epoch 52000:, Loss is 0.16891524195671082\n",
      "Epoch 53000:, Loss is 0.16891524195671082\n",
      "Epoch 54000:, Loss is 0.16891524195671082\n",
      "Epoch 55000:, Loss is 0.16891524195671082\n",
      "Epoch 56000:, Loss is 0.16891524195671082\n",
      "Epoch 57000:, Loss is 0.16891524195671082\n",
      "Epoch 58000:, Loss is 0.16891524195671082\n",
      "Epoch 59000:, Loss is 0.16891524195671082\n",
      "Epoch 60000:, Loss is 0.16891524195671082\n",
      "Epoch 61000:, Loss is 0.16891524195671082\n",
      "Epoch 62000:, Loss is 0.16891524195671082\n",
      "Epoch 63000:, Loss is 0.16891524195671082\n",
      "Epoch 64000:, Loss is 0.16891524195671082\n",
      "Epoch 65000:, Loss is 0.16891524195671082\n",
      "Epoch 66000:, Loss is 0.16891524195671082\n",
      "Epoch 67000:, Loss is 0.16891524195671082\n",
      "Epoch 68000:, Loss is 0.16891524195671082\n",
      "Epoch 69000:, Loss is 0.16891524195671082\n",
      "Epoch 70000:, Loss is 0.16891524195671082\n",
      "Epoch 71000:, Loss is 0.16891524195671082\n",
      "Epoch 72000:, Loss is 0.16891524195671082\n",
      "Epoch 73000:, Loss is 0.16891524195671082\n",
      "Epoch 74000:, Loss is 0.16891524195671082\n",
      "Epoch 75000:, Loss is 0.16891524195671082\n",
      "Epoch 76000:, Loss is 0.16891524195671082\n",
      "Epoch 77000:, Loss is 0.16891524195671082\n",
      "Epoch 78000:, Loss is 0.16891524195671082\n",
      "Epoch 79000:, Loss is 0.16891524195671082\n",
      "Epoch 80000:, Loss is 0.16891524195671082\n",
      "Epoch 81000:, Loss is 0.16891524195671082\n",
      "Epoch 82000:, Loss is 0.16891524195671082\n",
      "Epoch 83000:, Loss is 0.16891524195671082\n",
      "Epoch 84000:, Loss is 0.16891524195671082\n",
      "Epoch 85000:, Loss is 0.16891524195671082\n",
      "Epoch 86000:, Loss is 0.16891524195671082\n",
      "Epoch 87000:, Loss is 0.16891524195671082\n",
      "Epoch 88000:, Loss is 0.16891524195671082\n",
      "Epoch 89000:, Loss is 0.16891524195671082\n",
      "Epoch 90000:, Loss is 0.16891524195671082\n",
      "Epoch 91000:, Loss is 0.16891524195671082\n",
      "Epoch 92000:, Loss is 0.16891524195671082\n",
      "Epoch 93000:, Loss is 0.16891524195671082\n",
      "Epoch 94000:, Loss is 0.16891524195671082\n",
      "Epoch 95000:, Loss is 0.16891524195671082\n",
      "Epoch 96000:, Loss is 0.16891524195671082\n",
      "Epoch 97000:, Loss is 0.16891524195671082\n",
      "Epoch 98000:, Loss is 0.16891524195671082\n",
      "Epoch 99000:, Loss is 0.16891524195671082\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    loss = criterian(outputs, targets)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch) % 1000 == 0:\n",
    "        print(f'Epoch {epoch}:, Loss is {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted, label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80d51ef78edf10dafe6390381350fe95ff353a7dfba1a29380139ac198de4789"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
